{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/favour_nerrise/Al-HaQ/venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pennylane --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "# sys.path.insert(1, \"/home/favour_nerrise/Al-HaQ\")\n",
    "from src.preprocessing import FakeTweetsDataset, create_mini_batch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import models.qnn as qnn\n",
    "\n",
    "from transformers import AutoTokenizer, XLNetForSequenceClassification\n",
    "from IPython.display import display, clear_output\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "os.environ[\"CURL_CA_BUNDLE\"] = \"\"\n",
    "os.environ[\"REQUESTS_CA_BUNDLE\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 56\n",
    "\n",
    "proxy = {\"http\": \"http://127.0.0.1:7890\", \"https\": \"http://127.0.0.1:7890\"}\n",
    "MODEL_NAME = \"xlnet-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QCNN(\n",
       "  (qcnn_layer): <Quantum Torch Layer: func=qcnn4>\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "cla_model = XLNetForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "\n",
    "qcnn = qnn.QCNN(4)\n",
    "\n",
    "data_path = \"datasets/twitter_dataset\"\n",
    "trainset = FakeTweetsDataset(\"train\", tokenizer=tokenizer, path=data_path)\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, collate_fn=create_mini_batch)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cla_model.to(device)\n",
    "qcnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data length:114069\n"
     ]
    }
   ],
   "source": [
    "cla_model.train()\n",
    "qcnn.train()\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [{\"params\": cla_model.parameters()}, {\"params\": qcnn.parameters()}], lr=1e-3\n",
    ")\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "print(f\"data length:{trainset.len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]\n",
      "target\n",
      "0    45139\n",
      "1    68930\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0, cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     16\u001b[0m q_input \u001b[38;5;241m=\u001b[39m cla_model(\n\u001b[1;32m     17\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39mtokens_tensors,\n\u001b[1;32m     18\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39msegments_tensors,\n\u001b[1;32m     19\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mmasks_tensors,\n\u001b[1;32m     20\u001b[0m )[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 22\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mqcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(outputs, labels)\n\u001b[1;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Al-HaQ/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Al-HaQ/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Al-HaQ/models/qnn.py:90\u001b[0m, in \u001b[0;36mQCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     88\u001b[0m x \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mmin\u001b[39m) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mmax\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mmin\u001b[39m)\n\u001b[1;32m     89\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m x \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mpi\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqcnn_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Al-HaQ/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Al-HaQ/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Al-HaQ/venv/lib/python3.10/site-packages/pennylane/qnn/torch.py:402\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    399\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(inputs, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, inputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    401\u001b[0m \u001b[38;5;66;03m# calculate the forward pass as usual\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_qnode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;66;03m# reshape to the correct number of batch dims\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_batch_dim:\n",
      "File \u001b[0;32m~/Al-HaQ/venv/lib/python3.10/site-packages/pennylane/qnn/torch.py:423\u001b[0m, in \u001b[0;36mTorchLayer._evaluate_qnode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluates the QNode for a single input datapoint.\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    tensor: output datapoint\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    419\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_arg: x},\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{arg: weight\u001b[38;5;241m.\u001b[39mto(x) \u001b[38;5;28;01mfor\u001b[39;00m arg, weight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqnode_weights\u001b[38;5;241m.\u001b[39mitems()},\n\u001b[1;32m    422\u001b[0m }\n\u001b[0;32m--> 423\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqnode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mtype(x\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Al-HaQ/venv/lib/python3.10/site-packages/pennylane/workflow/qnode.py:1048\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         full_transform_program\u001b[38;5;241m.\u001b[39m_set_all_argnums(\n\u001b[1;32m   1044\u001b[0m             \u001b[38;5;28mself\u001b[39m, args, kwargs, argnums\n\u001b[1;32m   1045\u001b[0m         )  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# pylint: disable=unexpected-keyword-arg\u001b[39;00m\n\u001b[0;32m-> 1048\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_program\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_transform_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverride_shots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_shots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1060\u001b[0m res \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
      "File \u001b[0;32m~/Al-HaQ/venv/lib/python3.10/site-packages/pennylane/workflow/execution.py:684\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, device, gradient_fn, interface, transform_program, config, grad_on_execution, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion, device_batch_transform, device_vjp)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;66;03m# Exiting early if we do not need to deal with an interface boundary\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_interface_boundary_required:\n\u001b[0;32m--> 684\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43minner_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m post_processing(results)\n\u001b[1;32m    687\u001b[0m _grad_on_execution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Al-HaQ/venv/lib/python3.10/site-packages/pennylane/workflow/execution.py:283\u001b[0m, in \u001b[0;36m_make_inner_execute.<locals>.inner_execute\u001b[0;34m(tapes, **_)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_only:\n\u001b[1;32m    282\u001b[0m     tapes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(qml\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mconvert_to_numpy_parameters(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tapes)\n\u001b[0;32m--> 283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcached_device_execution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Al-HaQ/venv/lib/python3.10/site-packages/pennylane/workflow/execution.py:361\u001b[0m, in \u001b[0;36mcache_execute.<locals>.wrapper\u001b[0;34m(tapes, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(cache, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache):\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# No caching. Simply execute the execution function\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# and return the results.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \n\u001b[1;32m    360\u001b[0m     \u001b[38;5;66;03m# must convert to list as new device interface returns tuples\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (res, []) \u001b[38;5;28;01mif\u001b[39;00m return_tuple \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[1;32m    364\u001b[0m execution_tapes \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Al-HaQ/venv/lib/python3.10/site-packages/pennylane/devices/modifiers/simulator_tracking.py:30\u001b[0m, in \u001b[0;36m_track_execute.<locals>.execute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(untracked_execute)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, circuits, execution_config\u001b[38;5;241m=\u001b[39mDefaultExecutionConfig):\n\u001b[0;32m---> 30\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43muntracked_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(circuits, QuantumScript):\n\u001b[1;32m     32\u001b[0m         batch \u001b[38;5;241m=\u001b[39m (circuits,)\n",
      "File \u001b[0;32m~/Al-HaQ/venv/lib/python3.10/site-packages/pennylane/devices/modifiers/single_tape_support.py:32\u001b[0m, in \u001b[0;36m_make_execute.<locals>.execute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m     30\u001b[0m     is_single_circuit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     circuits \u001b[38;5;241m=\u001b[39m (circuits,)\n\u001b[0;32m---> 32\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m is_single_circuit \u001b[38;5;28;01melse\u001b[39;00m results\n",
      "File \u001b[0;32m~/Al-HaQ/venv/lib/python3.10/site-packages/pennylane/devices/default_qubit.py:553\u001b[0m, in \u001b[0;36mDefaultQubit.execute\u001b[0;34m(self, circuits, execution_config)\u001b[0m\n\u001b[1;32m    547\u001b[0m interface \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    548\u001b[0m     execution_config\u001b[38;5;241m.\u001b[39minterface\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m execution_config\u001b[38;5;241m.\u001b[39mgradient_method \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackprop\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    551\u001b[0m )\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_workers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m            \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprng_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prng_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdebugger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_debugger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m            \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcircuits\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    565\u001b[0m vanilla_circuits \u001b[38;5;241m=\u001b[39m [convert_to_numpy_parameters(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m circuits]\n\u001b[1;32m    566\u001b[0m seeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng\u001b[38;5;241m.\u001b[39mintegers(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m31\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(vanilla_circuits))\n",
      "File \u001b[0;32m~/Al-HaQ/venv/lib/python3.10/site-packages/pennylane/devices/default_qubit.py:554\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    547\u001b[0m interface \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    548\u001b[0m     execution_config\u001b[38;5;241m.\u001b[39minterface\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m execution_config\u001b[38;5;241m.\u001b[39mgradient_method \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackprop\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    551\u001b[0m )\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_workers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m--> 554\u001b[0m         \u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m            \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprng_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prng_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdebugger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_debugger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m            \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m circuits\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    565\u001b[0m vanilla_circuits \u001b[38;5;241m=\u001b[39m [convert_to_numpy_parameters(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m circuits]\n\u001b[1;32m    566\u001b[0m seeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng\u001b[38;5;241m.\u001b[39mintegers(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m31\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(vanilla_circuits))\n",
      "File \u001b[0;32m~/Al-HaQ/venv/lib/python3.10/site-packages/pennylane/devices/qubit/simulate.py:260\u001b[0m, in \u001b[0;36msimulate\u001b[0;34m(circuit, rng, prng_key, debugger, interface, state_cache)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m circuit\u001b[38;5;241m.\u001b[39mshots \u001b[38;5;129;01mand\u001b[39;00m has_mid_circuit_measurements(circuit):\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m simulate_native_mcm(\n\u001b[1;32m    258\u001b[0m         circuit, rng\u001b[38;5;241m=\u001b[39mrng, prng_key\u001b[38;5;241m=\u001b[39mprng_key, debugger\u001b[38;5;241m=\u001b[39mdebugger, interface\u001b[38;5;241m=\u001b[39minterface\n\u001b[1;32m    259\u001b[0m     )\n\u001b[0;32m--> 260\u001b[0m state, is_state_batched \u001b[38;5;241m=\u001b[39m \u001b[43mget_final_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebugger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebugger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m     state_cache[circuit\u001b[38;5;241m.\u001b[39mhash] \u001b[38;5;241m=\u001b[39m state\n",
      "File \u001b[0;32m~/Al-HaQ/venv/lib/python3.10/site-packages/pennylane/devices/qubit/simulate.py:139\u001b[0m, in \u001b[0;36mget_final_state\u001b[0;34m(circuit, debugger, interface, mid_measurements)\u001b[0m\n\u001b[1;32m    137\u001b[0m is_state_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(prep \u001b[38;5;129;01mand\u001b[39;00m prep\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m circuit\u001b[38;5;241m.\u001b[39moperations[\u001b[38;5;28mbool\u001b[39m(prep) :]:\n\u001b[0;32m--> 139\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[43mapply_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_state_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_state_batched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdebugger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebugger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmid_measurements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmid_measurements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# Handle postselection on mid-circuit measurements\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op, qml\u001b[38;5;241m.\u001b[39mProjector):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/functools.py:889\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    887\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 889\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Al-HaQ/venv/lib/python3.10/site-packages/pennylane/devices/qubit/apply_operation.py:204\u001b[0m, in \u001b[0;36mapply_operation\u001b[0;34m(op, state, is_state_batched, debugger, **_)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;129m@singledispatch\u001b[39m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_operation\u001b[39m(\n\u001b[1;32m    154\u001b[0m     op: qml\u001b[38;5;241m.\u001b[39moperation\u001b[38;5;241m.\u001b[39mOperator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_,\n\u001b[1;32m    159\u001b[0m ):\n\u001b[1;32m    160\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply and operator to a given state.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_operation_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_state_batched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebugger\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Al-HaQ/venv/lib/python3.10/site-packages/pennylane/devices/qubit/apply_operation.py:214\u001b[0m, in \u001b[0;36m_apply_operation_default\u001b[0;34m(op, state, is_state_batched, debugger)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The default behaviour of apply_operation, accessed through the standard dispatch\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03mof apply_operation, as well as conditionally in other dispatches.\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28mlen\u001b[39m(op\u001b[38;5;241m.\u001b[39mwires) \u001b[38;5;241m<\u001b[39m EINSUM_OP_WIRECOUNT_PERF_THRESHOLD\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m math\u001b[38;5;241m.\u001b[39mndim(state) \u001b[38;5;241m<\u001b[39m EINSUM_STATE_WIRECOUNT_PERF_THRESHOLD\n\u001b[1;32m    213\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m (op\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;129;01mand\u001b[39;00m is_state_batched):\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_operation_einsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_state_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_state_batched\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m apply_operation_tensordot(op, state, is_state_batched\u001b[38;5;241m=\u001b[39mis_state_batched)\n",
      "File \u001b[0;32m~/Al-HaQ/venv/lib/python3.10/site-packages/pennylane/devices/qubit/apply_operation.py:102\u001b[0m, in \u001b[0;36mapply_operation_einsum\u001b[0;34m(op, state, is_state_batched)\u001b[0m\n\u001b[1;32m     99\u001b[0m         op\u001b[38;5;241m.\u001b[39m_batch_size \u001b[38;5;241m=\u001b[39m batch_size  \u001b[38;5;66;03m# pylint:disable=protected-access\u001b[39;00m\n\u001b[1;32m    100\u001b[0m reshaped_mat \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mreshape(mat, new_mat_shape)\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43meinsum_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreshaped_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Al-HaQ/venv/lib/python3.10/site-packages/pennylane/math/multi_dispatch.py:539\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(indices, like, optimize, *operands)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m like \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    538\u001b[0m     like \u001b[38;5;241m=\u001b[39m get_interface(\u001b[38;5;241m*\u001b[39moperands)\n\u001b[0;32m--> 539\u001b[0m operands \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoerce\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlike\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m like \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;66;03m# torch einsum doesn't support the optimize keyword argument\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39meinsum(indices, \u001b[38;5;241m*\u001b[39moperands, like\u001b[38;5;241m=\u001b[39mlike)\n",
      "File \u001b[0;32m~/Al-HaQ/venv/lib/python3.10/site-packages/autoray/autoray.py:80\u001b[0m, in \u001b[0;36mdo\u001b[0;34m(fn, like, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Do function named ``fn`` on ``(*args, **kwargs)``, peforming single\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03mdispatch to retrieve ``fn`` based on whichever library defines the class of\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mthe ``args[0]``, or the ``like`` keyword argument if specified.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    <tf.Tensor: id=91, shape=(3, 3), dtype=float32>\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m backend \u001b[38;5;241m=\u001b[39m choose_backend(fn, \u001b[38;5;241m*\u001b[39margs, like\u001b[38;5;241m=\u001b[39mlike, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_lib_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Al-HaQ/venv/lib/python3.10/site-packages/pennylane/math/single_dispatch.py:606\u001b[0m, in \u001b[0;36m_coerce_types_torch\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(device_set) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;66;03m# GPU specific case\u001b[39;00m\n\u001b[1;32m    605\u001b[0m     device_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m device_set)\n\u001b[0;32m--> 606\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    607\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on the same device, but found at least two devices, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    608\u001b[0m     )\n\u001b[1;32m    610\u001b[0m device \u001b[38;5;241m=\u001b[39m device_set\u001b[38;5;241m.\u001b[39mpop() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(device_set) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    611\u001b[0m tensors \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mas_tensor(t, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tensors]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0, cpu!"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{NUM_EPOCHS}]\")\n",
    "\n",
    "    for batch_idx, data in enumerate(trainloader):\n",
    "\n",
    "        tokens_tensors, segments_tensors, masks_tensors, labels = [\n",
    "            t.to(device) for t in data\n",
    "        ]\n",
    "\n",
    "        # labels = labels.type(torch.LongTensor).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        q_input = cla_model(\n",
    "            input_ids=tokens_tensors,\n",
    "            token_type_ids=segments_tensors,\n",
    "            attention_mask=masks_tensors,\n",
    "        )[0].to(device)\n",
    "\n",
    "        outputs = qcnn(q_input)\n",
    "\n",
    "        loss = loss_func(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = torch.argmax(outputs, dim=1)\n",
    "        train_acc = accuracy_score(pred.cpu().tolist(), labels.cpu().tolist())\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    print(f\"acc={train_acc}, loss={train_loss / (batch_idx + 1):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cla_model, \"results/xlnet_twitter.pth\")\n",
    "torch.save(qcnn.state_dict(), \"results/qcnn_twitter_tx.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
